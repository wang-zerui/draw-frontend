(window["webpackJsonp"]=window["webpackJsonp"]||[]).push([["chunk-2fc4323b"],{"4dc8":function(n,e,r){"use strict";r("5836")},5836:function(n,e,r){},d630:function(n,e,r){"use strict";r.r(e);var t=function(){var n=this,e=n.$createElement,r=n._self._c||e;return r("div",{staticClass:"hello"},[r("a-row",{staticStyle:{margin:"0 -12px"}},[r("a-col",{staticStyle:{padding:"0 12px"},attrs:{xl:12,lg:24,md:24,sm:24,xs:24}},[r("a-card",{attrs:{bodyStyle:{height:"800px","padding-right":"1px","padding-left":"1px","padding-top":"1px","padding-bottom":"0px"},title:n.title}},[r("codemirror",{attrs:{options:n.cmOptions},model:{value:n.code,callback:function(e){n.code=e},expression:"code"}})],1)],1),r("a-col",{staticStyle:{padding:"0 12px"},attrs:{xl:12,lg:24,md:24,sm:24,xs:24}},[r("a-card",{attrs:{bodyStyle:{height:"800px","padding-right":"1px","padding-left":"1px","padding-top":"1px","padding-bottom":"0px"},title:n.title1}},[r("codemirror",{attrs:{options:n.cmOptions},model:{value:n.code1,callback:function(e){n.code1=e},expression:"code1"}})],1)],1)],1)],1)},T=[],o=(r("db91"),r("b866"),r("31c5"),r("10b2"),r("4ba6"),r("8c33"),r("7289"),r("2aed"),r("d72f"),r("b933"),r("0b6c"),r("2e6e"),"import Token as TK\nclass Lexer:\n    # 构造函数，初始化文件流对象\n    def __init__(self, filePath):\n        self.index = 1\n        self.filePath = filePath\n        self.tokenBuffer = ''\n        try:\n            self.file_ptr = open(self.filePath, 'r', encoding='utf-8')\n        except IOError:\n            print(\"Error: 没有找到文件或读取文件失败\")\n    # 析构函数，在词法分析正常结束时关闭流对象\n    def __del__(self):\n        print(\"析构start~ file close\")\n        self.file_ptr.close()\n    \n    \n    # 读取一个字符的函数\n    def getChar(self):\n        # 不用做是否读到文件尾的判断，在getToken中使用额外逻辑判断\n        ch = self.file_ptr.read(1)\n        return ch.upper()\n    \n\n    # 回退一个字符\n    def backChar(self, char):\n        if char != '':\n            self.file_ptr.seek(self.file_ptr.tell() - 1)\n\n    def backMyChar(self, char, point):\n        if char != '':\n            self.file_ptr.seek(point)\n\n    # 把字符加入目前的缓冲区的Token中\n    def putChar(self, char):\n        self.tokenBuffer += char\n\n    \n    # 判断这个token具体是tokenTable中的哪个Token，返回对应Token的信息\n    # 若是查不到，返回默认错误字符\n    def JudgeKeyToken(self):\n        return TK.TokenTable.get(self.tokenBuffer, TK.Tokens(TK.TokenType.ERRORTOKEN, self.tokenBuffer))\n    \n    # -------------------------词法分析主驱动函数---------------------------------\n    # 在语法分析的过程中调用此函数，每调用一次获得一个Token\n    # 该函数本质是模拟DFA的一个实现，通过遍历输入流，检测所有可能的情况的Token是什么\n    def getToken(self):\n        # 清空上次的缓冲区\n        self.tokenBuffer = ''\n        # 识别到的字符\n        current_char = ''\n        # 最终的Token对象，在递归下降分析中进行匹配\n        current_token = None\n        while(1):\n            # 循环控制，跳过符号前的所有的空格和换行，同时判断是否到达文件的末尾\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            # 空字符判断，读到文件的末尾\n            if current_char == '':\n                current_token = TK.Tokens(TK.TokenType.NONTOKEN, '')\n                return current_token\n            # 维护一个Index，为语法分析提供合适的报错需求接口\n            elif current_char == '\n':\n                self.index += 1\n            # 空格的判断，处理掉所有的空格\n            elif not current_char.isspace():\n                break\n            # current_char = pre_proccess()\n        # 此时，current_char就是第一个非空白的字符(已经获取到了，不用再次获取)\n\n\n        # 将此字符放入缓冲区\n        self.putChar(current_char)\n\n        # 以字母打头的字母串\n        if current_char.isalpha():\n            while(1):\n                last_char = self.file_ptr.tell()\n                current_char = self.getChar()\n                # 是字符，那么放入缓冲区\n                if current_char.isalnum():\n                    self.putChar(current_char)\n                else:\n                    break\n            # 结束循环时，已经移动到了当前字符的下一个字符上\n            # 比如遇到的是一个空格，那么此时已经移动到了空格的下一个字符上，如果此时的字符不是一个空格的话，那么是需要一个回退的操作的\n            # 当然，如果空格的下一个字符还是一个空格，那么其实这一步并不需要回退，下次再GetToken的时候会在预处理中跳过空格\n            self.backMyChar(current_char, last_char)\n            #self.backChar(current_char)\n            # token的匹配\n            current_token = self.JudgeKeyToken()\n            # 匹配后，输入序列放入：\n            current_token.lexeme = self.tokenBuffer\n            return current_token\n        \n        # 以数字打头的串\n        elif current_char.isdigit():\n            while(1):\n                last_char = self.file_ptr.tell()\n                current_char = self.getChar()\n                # digit+的表示\n                if current_char.isdigit():\n                    self.putChar(current_char)\n                else:\n                    break\n            # '.'的识别，且注意识别.后，后面一定是digit+\n            if current_char == '.':\n                self.putChar(current_char)\n                while(1):\n                    last_char = self.file_ptr.tell()\n                    current_char = self.getChar()\n                    # digit+的表示\n                    if current_char.isdigit():\n                        self.putChar(current_char)\n                    else:\n                        break\n            # 识别结束，回退字符\n            #self.backChar(current_char)\n            self.backMyChar(current_char, last_char)\n            # 不同于ID，这里不用查表，直接new Token，然后放入识别到的数字\n            current_token = TK.Tokens(TK.TokenType.CONST_ID, self.tokenBuffer, float(self.tokenBuffer))\n            return current_token\n        \n        # 分隔符\n        elif current_char == ';':\n            return TK.Tokens(TK.TokenType.SEMICO, \";\")\n        elif current_char == ',':\n            return TK.Tokens(TK.TokenType.COMMA, \",\")\n        elif current_char == '(':\n            return TK.Tokens(TK.TokenType.L_BRACKET, \"(\")\n        elif current_char == ')':\n            return TK.Tokens(TK.TokenType.R_BRACKET, \")\")\n        \n        # 用户字符串\n        elif current_char == \"'\":\n            # 先清除缓冲区中的单引号，title中不应该有引号\n            self.tokenBuffer = ''\n            current_char = self.getChar()\n            # 遇到匹配的尾单引号时进行匹配\n            while(current_char != \"'\" ):\n                # 如果已经是空字符或者是换行了，那么应该报错，单引号匹配有错误\n                if current_char == '' or current_char == '\n':\n                    self.backMyChar(current_char, last_char)\n                    #self.backChar(current_char)\n                    return TK.Tokens(TK.TokenType.ERRORTOKEN, \"缺少匹配的单引号\")\n                self.putChar(current_char)\n                current_char = self.getChar()\n            # 否则，肯定是遇到单引号，USER_STRING识别完毕。且已经移动到单引号的下一个字符，这里不用putChar\n            return TK.Tokens(TK.TokenType.USER_STRING, self.tokenBuffer)\n            \n        # 运算符\n        elif current_char == '+':\n            return TK.Tokens(TK.TokenType.PLUS, \"+\")\n        ## '-'要额外考虑是注释的情况\n        elif current_char == '-':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '-':\n                while current_char != '\n' and current_char != '':   \n                    last_char = self.file_ptr.tell()                 \n                    current_char = self.getChar()\n                # 不再是注释内容\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                # 假如就是注释，那么特别的，我们这里对getToken进行一次递归调用\n                return self.getToken()\n            else:\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                return TK.Tokens(TK.TokenType.MINUS,\"-\")\n        ## '**'要额外考虑乘方的情况\n        elif current_char == '*':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '*':\n                return TK.Tokens(TK.TokenType.POWER,\"**\")\n            else:\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                return TK.Tokens(TK.TokenType.MUL, \"*\")\n        ## '/'要额外考虑注释的情况\n        elif current_char == '/':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '/':\n                while current_char != '\n' and current_char != '':\n                    last_char = self.file_ptr.tell()\n                    current_char = self.getChar()\n                # 不再是注释\n                self.backMyChar(current_char, last_char)\n                #self.backChar(current_char)\n                # 已经识别了是注释，那么递归调用\n                return self.getToken()\n            else:\n                self.backMyChar(current_char, last_char)\n                #self.backChar(current_char)\n                return TK.Tokens(TK.TokenType.DIV, \"/\")\n        # 其余情况为错误字符串\n        else:\n            return TK.Tokens(TK.TokenType.ERRORTOKEN, self.tokenBuffer)"),c='from enum import Enum\nimport numpy as np\n\nclass TokenType(Enum):\n    # 常数\n    CONST_ID = \'CONST_ID\'\n    # 唯一参数T\n    T = \'T\'\n    # 支持函数：SIN COS TAN SQRT EXP LN\n    FUNC = \'FUNCTION\'\n    # 保留关键字\n    ## FOR T FROM 起点 TO 终点 STEP 步长 DRAW(x,y);\n    FOR = \'FOR\'\n    FROM = \'FROM\'\n    TO = \'TO\'\n    STEP = \'STEP\'\n    DRAW = \'DRAW\'\n    SCATTER = \'SCATTER\'\n    ## ORIGIN IS (x, y)\n    ORIGIN = \'ORIGIN\'\n    IS = \'IS\'\n    ## ROT IS (X, Y)\n    ROT = \'ROT\'\n    ## SCALE IS (X,Y)\n    SCALE = \'SCALE\'\n    ## IN [COLOR_NAME]\n    IN = \'IN\'\n    COLOR = \'COLOR\'\n    ## LINE[LINE_WIDTH][LINE_TYPE]\n    LINE = \'LINE\'\n    LINE_TYPE = \'LINE_TYPE\'\n    ## TITLE(\'USER_STRING\')\n    TITLE = \'TITLE\'\n    USER_STRING = \'USER_STRING\'\n    ## XLABEL(\'USER_STRING\'), YLABEL(\'USER_STRING\')\n    XLABEL = \'XLABEL\'\n    YLABEL = \'YLABEL\'\n    ## GRID ON GRID OFF\n    GRID = \'GRID\'\n    ON = \'ON\'\n    OFF = \'OFF\'\n    ## DYNAMIC ON DYNAMIC OFF\n    DYNAMIC = \'DYNAMIC\'\n    # 分隔符\n    SEMICO = ";"\n    L_BRACKET = "("\n    R_BRACKET = ")"\n    COMMA = ","\n    # 运算符\n    PLUS = \'+\'\n    MINUS = \'-\'\n    MUL = \'*\'\n    DIV = \'/\'\n    MOD = \'%\'\n    POWER = \'**\'\n    # 空记号 源程序结束\n    NONTOKEN = \'NULL\'\n    # 出错符号，非法输入\n    ERRORTOKEN = \'ERROR\'\n\n\nclass Tokens:\n    # 构造函数，默认情况下值为0，函数指针指向空\n    def __init__(self, tokenType, lexeme, value = 0.0, function = None):\n        self.tokenType = tokenType\n        self.lexeme = lexeme\n        self.value = value\n        self.function = function\n    # 展示token的内容，便于调试\n    def disp(self):\n        # print(\'{:<10s}|{:x<10s}|{:<10f}|{}\'.format(self.tokenType.name,  self.lexeme, self.value, self.function))\n        print(\'{:<30s}|{:<28s}\t|{:<10f}|{}\'.format(self.tokenType.name,  self.lexeme, self.value, self.function))\n\nTokenTable = {\n    # 常量：COUST_ID\n    "PI" : Tokens(TokenType.CONST_ID, "PI", 3.1415926, None),\n    "E"  : Tokens(TokenType.CONST_ID,"E",2.71828,None),\n    # 唯一变量T ：T\n    "T"  : Tokens(TokenType.T, "T"),\n    # 函数\n    "SIN": Tokens(TokenType.FUNC, "SIN", 0, np.sin),\n    "COS": Tokens(TokenType.FUNC, "COS", 0, np.cos),\n    "TAN": Tokens(TokenType.FUNC, "TAN", 0, np.tan),\n    "SQRT": Tokens(TokenType.FUNC, "SQRT", 0, np.sqrt),\n    "EXP": Tokens(TokenType.FUNC, "EXP", 0, np.exp),\n    "LN": Tokens(TokenType.FUNC, "LN", 0, np.log),\n    # 保留关键字\n    "ORIGIN":Tokens(TokenType.ORIGIN, "ORIGIN"),\n    "IS":Tokens(TokenType.IS, "IS"),\n    "ROT":Tokens(TokenType.ROT, "ROT"),\n    "SCALE":Tokens(TokenType.SCALE, "SCALE"),\n    "FOR":Tokens(TokenType.FOR, "FOR"),\n    "FROM":Tokens(TokenType.FROM, "FROM"),\n    "TO":Tokens(TokenType.TO, "TO"),\n    "STEP":Tokens(TokenType.STEP,"STEP"),\n    "DRAW":Tokens(TokenType.DRAW, "DRAW"),\n    "SCATTER":Tokens(TokenType.SCATTER,"SCATTER"),\n    "COLOR":Tokens(TokenType.COLOR, "COLOR"),\n    "LINE":Tokens(TokenType.LINE,"LINE"),\n    "DOTS":Tokens(TokenType.LINE_TYPE,"DOTS"),\n    "DASHED":Tokens(TokenType.LINE_TYPE,"DASHED"),\n    "SOLID":Tokens(TokenType.LINE_TYPE,"SOLID"),\n    "XLABEL":Tokens(TokenType.XLABEL,"XLABEL"),\n    "YLABEL":Tokens(TokenType.YLABEL,"YLABEL"),\n    "TITLE":Tokens(TokenType.TITLE,"TITLE"),\n    "GRID":Tokens(TokenType.GRID, "GRID"),\n    "ON":Tokens(TokenType.ON, "ON"),\n    "OFF":Tokens(TokenType.OFF, "OFF"),\n    "DYNAMIC":Tokens(TokenType.DYNAMIC, "DYNAMIC"),\n    # 颜色\n    "DIMGRAY":Tokens(TokenType.COLOR,"DIMGRAY"),\n    "GOLDENROD":Tokens(TokenType.COLOR,"GOLDENROD"),\n    "KHAKI":Tokens(TokenType.COLOR,"KHAKI"),\n    "DARKSEAGREEN":Tokens(TokenType.COLOR,"DARKSEAGREEN"),\n    "DARKKHAKI":Tokens(TokenType.COLOR,"DARKKHAKI"),\n    "PINK":Tokens(TokenType.COLOR,"PINK"),\n    "LIGHTSALMON":Tokens(TokenType.COLOR,"LIGHTSALMON"),\n    "LIGHTCORAL":Tokens(TokenType.COLOR,"LIGHTCORAL"),\n    "IN":Tokens(TokenType.IN, "IN")\n}',s={name:"Parser",data:function(){return{title1:"Lexer.py",title:"Token.py",code:o,code1:c,cmOptions:{autoCloseBrackets:!0,tabSize:4,styleActiveLine:!0,lineNumbers:!0,line:!0,mode:"text/x-python",theme:"idea",keyMap:"emacs"},option:{},updateOption:{},isImage:!1,isError:!1,isSuccess:!1,errorMsg:"",successMsg:"",collapsed:!1}},methods:{onCmReady:function(n){console.log("the editor is readied!",n)},onCmFocus:function(n){console.log("the editor is focused!",n)},onCmCodeChange:function(n){console.log("this is new code",n),this.code=n}},computed:{},mounted:function(){},components:{}},a=s,l=(r("4dc8"),r("2877")),f=Object(l["a"])(a,t,T,!1,null,null,null);e["default"]=f.exports}}]);
//# sourceMappingURL=chunk-2fc4323b.70367a6a.js.map