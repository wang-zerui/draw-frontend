{"version":3,"sources":["webpack:///./src/components/Lexer.vue?518d","webpack:///./src/components/Lexer.vue?ceb6","webpack:///src/components/Lexer.vue","webpack:///./src/components/Lexer.vue?3205","webpack:///./src/components/Lexer.vue?d25f"],"names":["render","_vm","this","_h","$createElement","_c","_self","staticClass","staticStyle","attrs","height","title","cmOptions","model","value","callback","$$v","code","expression","title1","code1","staticRenderFns","name","data","autoCloseBrackets","tabSize","styleActiveLine","lineNumbers","line","mode","theme","keyMap","option","updateOption","isImage","isError","isSuccess","errorMsg","successMsg","collapsed","methods","onCmReady","console","log","cm","onCmFocus","onCmCodeChange","newCode","computed","mounted","components","component"],"mappings":"kHAAA,W,gECAA,IAAIA,EAAS,WAAa,IAAIC,EAAIC,KAASC,EAAGF,EAAIG,eAAmBC,EAAGJ,EAAIK,MAAMD,IAAIF,EAAG,OAAOE,EAAG,MAAM,CAACE,YAAY,SAAS,CAACF,EAAG,QAAQ,CAACG,YAAY,CAAC,OAAS,YAAY,CAACH,EAAG,QAAQ,CAACG,YAAY,CAAC,QAAU,UAAUC,MAAM,CAAC,GAAK,GAAG,GAAK,GAAG,GAAK,GAAG,GAAK,GAAG,GAAK,KAAK,CAACJ,EAAG,SAAS,CAACI,MAAM,CAAC,UAAY,CACpSC,OAAQ,QACR,gBAAiB,MACjB,eAAgB,MAChB,cAAe,MACf,iBAAkB,OAClB,MAAQT,EAAIU,QAAQ,CAACN,EAAG,aAAa,CAACI,MAAM,CAAC,QAAUR,EAAIW,WAAWC,MAAM,CAACC,MAAOb,EAAQ,KAAEc,SAAS,SAAUC,GAAMf,EAAIgB,KAAKD,GAAKE,WAAW,WAAW,IAAI,GAAGb,EAAG,QAAQ,CAACG,YAAY,CAAC,QAAU,UAAUC,MAAM,CAAC,GAAK,GAAG,GAAK,GAAG,GAAK,GAAG,GAAK,GAAG,GAAK,KAAK,CAACJ,EAAG,SAAS,CAACI,MAAM,CAAC,UAAY,CACjSC,OAAQ,QACR,gBAAiB,MACjB,eAAgB,MAChB,cAAe,MACf,iBAAkB,OAClB,MAAQT,EAAIkB,SAAS,CAACd,EAAG,aAAa,CAACI,MAAM,CAAC,QAAUR,EAAIW,WAAWC,MAAM,CAACC,MAAOb,EAAS,MAAEc,SAAS,SAAUC,GAAMf,EAAImB,MAAMJ,GAAKE,WAAW,YAAY,IAAI,IAAI,IAAI,IACjLG,EAAkB,GC0DtB,G,wHAAA,y4OAwMA,0yHAwHA,GACEC,KAAM,SACNC,KAFF,WAGI,MAAO,CACLJ,OAAQ,WACRR,MAAO,WACPM,KAAN,EACMG,MAAN,EACMR,UAAW,CACTY,mBAAmB,EACnBC,QAAS,EACTC,iBAAiB,EACjBC,aAAa,EACbC,MAAM,EACNC,KAAM,gBACNC,MAAO,OACPC,OAAQ,SAEVC,OAAQ,GACRC,aAAc,GACdC,SAAS,EACTC,SAAS,EACTC,WAAW,EACXC,SAAU,GACVC,WAAY,GACZC,WAAW,IAGfC,QAAS,CACPC,UADJ,SACA,GACMC,QAAQC,IAAI,yBAA0BC,IAExCC,UAJJ,SAIA,GACMH,QAAQC,IAAI,yBAA0BC,IAExCE,eAPJ,SAOA,GACMJ,QAAQC,IAAI,mBAAoBI,GAChC7C,KAAKe,KAAO8B,IAGhBC,SAAU,GACVC,QAzCF,aA0CEC,WAAY,ICjbiU,I,wBCQ3UC,EAAY,eACd,EACAnD,EACAqB,GACA,EACA,KACA,KACA,MAIa,aAAA8B,E","file":"js/chunk-2fc4323b.70367a6a.js","sourcesContent":["export * from \"-!../../node_modules/mini-css-extract-plugin/dist/loader.js??ref--7-oneOf-1-0!../../node_modules/css-loader/dist/cjs.js??ref--7-oneOf-1-1!../../node_modules/vue-loader/lib/loaders/stylePostLoader.js!../../node_modules/postcss-loader/src/index.js??ref--7-oneOf-1-2!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Lexer.vue?vue&type=style&index=0&lang=css&\"","var render = function () {var _vm=this;var _h=_vm.$createElement;var _c=_vm._self._c||_h;return _c('div',{staticClass:\"hello\"},[_c('a-row',{staticStyle:{\"margin\":\"0 -12px\"}},[_c('a-col',{staticStyle:{\"padding\":\"0 12px\"},attrs:{\"xl\":12,\"lg\":24,\"md\":24,\"sm\":24,\"xs\":24}},[_c('a-card',{attrs:{\"bodyStyle\":{\n          height: '800px',\n          'padding-right': '1px',\n          'padding-left': '1px',\n          'padding-top': '1px',\n          'padding-bottom': '0px',\n        },\"title\":_vm.title}},[_c('codemirror',{attrs:{\"options\":_vm.cmOptions},model:{value:(_vm.code),callback:function ($$v) {_vm.code=$$v},expression:\"code\"}})],1)],1),_c('a-col',{staticStyle:{\"padding\":\"0 12px\"},attrs:{\"xl\":12,\"lg\":24,\"md\":24,\"sm\":24,\"xs\":24}},[_c('a-card',{attrs:{\"bodyStyle\":{\n          height: '800px',\n          'padding-right': '1px',\n          'padding-left': '1px',\n          'padding-top': '1px',\n          'padding-bottom': '0px',\n        },\"title\":_vm.title1}},[_c('codemirror',{attrs:{\"options\":_vm.cmOptions},model:{value:(_vm.code1),callback:function ($$v) {_vm.code1=$$v},expression:\"code1\"}})],1)],1)],1)],1)}\nvar staticRenderFns = []\n\nexport { render, staticRenderFns }","<template>\n  <div class=\"hello\">\n    <a-row style=\"margin: 0 -12px\">\n      <a-col\n        style=\"padding: 0 12px\"\n        :xl=\"12\"\n        :lg=\"24\"\n        :md=\"24\"\n        :sm=\"24\"\n        :xs=\"24\"\n      >\n        <a-card\n          :bodyStyle=\"{\n            height: '800px',\n            'padding-right': '1px',\n            'padding-left': '1px',\n            'padding-top': '1px',\n            'padding-bottom': '0px',\n          }\"\n          :title=\"title\"\n        >\n          <codemirror v-model=\"code\" :options=\"cmOptions\" />\n        </a-card>\n      </a-col>\n      <a-col\n        style=\"padding: 0 12px\"\n        :xl=\"12\"\n        :lg=\"24\"\n        :md=\"24\"\n        :sm=\"24\"\n        :xs=\"24\"\n      >\n        <a-card\n          :bodyStyle=\"{\n            height: '800px',\n            'padding-right': '1px',\n            'padding-left': '1px',\n            'padding-top': '1px',\n            'padding-bottom': '0px',\n          }\"\n          :title=\"title1\"\n        >\n          <codemirror v-model=\"code1\" :options=\"cmOptions\" />\n        </a-card>\n      </a-col>\n    </a-row>\n  </div>\n</template>\n<script>\n// language\nimport \"codemirror/mode/python/python.js\";\n\n// theme css\nimport \"codemirror/theme/idea.css\";\n\n// require active-line.js\nimport \"codemirror/addon/selection/active-line.js\";\n\n// closebrackets\nimport \"codemirror/addon/edit/closebrackets.js\";\n\n// keyMap\nimport \"codemirror/mode/clike/clike.js\";\nimport \"codemirror/addon/edit/matchbrackets.js\";\nimport \"codemirror/addon/comment/comment.js\";\nimport \"codemirror/addon/dialog/dialog.js\";\nimport \"codemirror/addon/dialog/dialog.css\";\nimport \"codemirror/addon/search/searchcursor.js\";\nimport \"codemirror/addon/search/search.js\";\nimport \"codemirror/keymap/emacs.js\";\n\nconst code = `import Token as TK\nclass Lexer:\n    # 构造函数，初始化文件流对象\n    def __init__(self, filePath):\n        self.index = 1\n        self.filePath = filePath\n        self.tokenBuffer = ''\n        try:\n            self.file_ptr = open(self.filePath, 'r', encoding='utf-8')\n        except IOError:\n            print(\"Error: 没有找到文件或读取文件失败\")\n    # 析构函数，在词法分析正常结束时关闭流对象\n    def __del__(self):\n        print(\"析构start~ file close\")\n        self.file_ptr.close()\n    \n    \n    # 读取一个字符的函数\n    def getChar(self):\n        # 不用做是否读到文件尾的判断，在getToken中使用额外逻辑判断\n        ch = self.file_ptr.read(1)\n        return ch.upper()\n    \n\n    # 回退一个字符\n    def backChar(self, char):\n        if char != '':\n            self.file_ptr.seek(self.file_ptr.tell() - 1)\n\n    def backMyChar(self, char, point):\n        if char != '':\n            self.file_ptr.seek(point)\n\n    # 把字符加入目前的缓冲区的Token中\n    def putChar(self, char):\n        self.tokenBuffer += char\n\n    \n    # 判断这个token具体是tokenTable中的哪个Token，返回对应Token的信息\n    # 若是查不到，返回默认错误字符\n    def JudgeKeyToken(self):\n        return TK.TokenTable.get(self.tokenBuffer, TK.Tokens(TK.TokenType.ERRORTOKEN, self.tokenBuffer))\n    \n    # -------------------------词法分析主驱动函数---------------------------------\n    # 在语法分析的过程中调用此函数，每调用一次获得一个Token\n    # 该函数本质是模拟DFA的一个实现，通过遍历输入流，检测所有可能的情况的Token是什么\n    def getToken(self):\n        # 清空上次的缓冲区\n        self.tokenBuffer = ''\n        # 识别到的字符\n        current_char = ''\n        # 最终的Token对象，在递归下降分析中进行匹配\n        current_token = None\n        while(1):\n            # 循环控制，跳过符号前的所有的空格和换行，同时判断是否到达文件的末尾\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            # 空字符判断，读到文件的末尾\n            if current_char == '':\n                current_token = TK.Tokens(TK.TokenType.NONTOKEN, '')\n                return current_token\n            # 维护一个Index，为语法分析提供合适的报错需求接口\n            elif current_char == '\\n':\n                self.index += 1\n            # 空格的判断，处理掉所有的空格\n            elif not current_char.isspace():\n                break\n            # current_char = pre_proccess()\n        # 此时，current_char就是第一个非空白的字符(已经获取到了，不用再次获取)\n\n\n        # 将此字符放入缓冲区\n        self.putChar(current_char)\n\n        # 以字母打头的字母串\n        if current_char.isalpha():\n            while(1):\n                last_char = self.file_ptr.tell()\n                current_char = self.getChar()\n                # 是字符，那么放入缓冲区\n                if current_char.isalnum():\n                    self.putChar(current_char)\n                else:\n                    break\n            # 结束循环时，已经移动到了当前字符的下一个字符上\n            # 比如遇到的是一个空格，那么此时已经移动到了空格的下一个字符上，如果此时的字符不是一个空格的话，那么是需要一个回退的操作的\n            # 当然，如果空格的下一个字符还是一个空格，那么其实这一步并不需要回退，下次再GetToken的时候会在预处理中跳过空格\n            self.backMyChar(current_char, last_char)\n            #self.backChar(current_char)\n            # token的匹配\n            current_token = self.JudgeKeyToken()\n            # 匹配后，输入序列放入：\n            current_token.lexeme = self.tokenBuffer\n            return current_token\n        \n        # 以数字打头的串\n        elif current_char.isdigit():\n            while(1):\n                last_char = self.file_ptr.tell()\n                current_char = self.getChar()\n                # digit+的表示\n                if current_char.isdigit():\n                    self.putChar(current_char)\n                else:\n                    break\n            # '.'的识别，且注意识别.后，后面一定是digit+\n            if current_char == '.':\n                self.putChar(current_char)\n                while(1):\n                    last_char = self.file_ptr.tell()\n                    current_char = self.getChar()\n                    # digit+的表示\n                    if current_char.isdigit():\n                        self.putChar(current_char)\n                    else:\n                        break\n            # 识别结束，回退字符\n            #self.backChar(current_char)\n            self.backMyChar(current_char, last_char)\n            # 不同于ID，这里不用查表，直接new Token，然后放入识别到的数字\n            current_token = TK.Tokens(TK.TokenType.CONST_ID, self.tokenBuffer, float(self.tokenBuffer))\n            return current_token\n        \n        # 分隔符\n        elif current_char == ';':\n            return TK.Tokens(TK.TokenType.SEMICO, \";\")\n        elif current_char == ',':\n            return TK.Tokens(TK.TokenType.COMMA, \",\")\n        elif current_char == '(':\n            return TK.Tokens(TK.TokenType.L_BRACKET, \"(\")\n        elif current_char == ')':\n            return TK.Tokens(TK.TokenType.R_BRACKET, \")\")\n        \n        # 用户字符串\n        elif current_char == \"'\":\n            # 先清除缓冲区中的单引号，title中不应该有引号\n            self.tokenBuffer = ''\n            current_char = self.getChar()\n            # 遇到匹配的尾单引号时进行匹配\n            while(current_char != \"'\" ):\n                # 如果已经是空字符或者是换行了，那么应该报错，单引号匹配有错误\n                if current_char == '' or current_char == '\\n':\n                    self.backMyChar(current_char, last_char)\n                    #self.backChar(current_char)\n                    return TK.Tokens(TK.TokenType.ERRORTOKEN, \"缺少匹配的单引号\")\n                self.putChar(current_char)\n                current_char = self.getChar()\n            # 否则，肯定是遇到单引号，USER_STRING识别完毕。且已经移动到单引号的下一个字符，这里不用putChar\n            return TK.Tokens(TK.TokenType.USER_STRING, self.tokenBuffer)\n            \n        # 运算符\n        elif current_char == '+':\n            return TK.Tokens(TK.TokenType.PLUS, \"+\")\n        ## '-'要额外考虑是注释的情况\n        elif current_char == '-':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '-':\n                while current_char != '\\n' and current_char != '':   \n                    last_char = self.file_ptr.tell()                 \n                    current_char = self.getChar()\n                # 不再是注释内容\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                # 假如就是注释，那么特别的，我们这里对getToken进行一次递归调用\n                return self.getToken()\n            else:\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                return TK.Tokens(TK.TokenType.MINUS,\"-\")\n        ## '**'要额外考虑乘方的情况\n        elif current_char == '*':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '*':\n                return TK.Tokens(TK.TokenType.POWER,\"**\")\n            else:\n                #self.backChar(current_char)\n                self.backMyChar(current_char, last_char)\n                return TK.Tokens(TK.TokenType.MUL, \"*\")\n        ## '/'要额外考虑注释的情况\n        elif current_char == '/':\n            last_char = self.file_ptr.tell()\n            current_char = self.getChar()\n            if current_char == '/':\n                while current_char != '\\n' and current_char != '':\n                    last_char = self.file_ptr.tell()\n                    current_char = self.getChar()\n                # 不再是注释\n                self.backMyChar(current_char, last_char)\n                #self.backChar(current_char)\n                # 已经识别了是注释，那么递归调用\n                return self.getToken()\n            else:\n                self.backMyChar(current_char, last_char)\n                #self.backChar(current_char)\n                return TK.Tokens(TK.TokenType.DIV, \"/\")\n        # 其余情况为错误字符串\n        else:\n            return TK.Tokens(TK.TokenType.ERRORTOKEN, self.tokenBuffer)`\nconst code1 = `from enum import Enum\nimport numpy as np\n\nclass TokenType(Enum):\n    # 常数\n    CONST_ID = 'CONST_ID'\n    # 唯一参数T\n    T = 'T'\n    # 支持函数：SIN COS TAN SQRT EXP LN\n    FUNC = 'FUNCTION'\n    # 保留关键字\n    ## FOR T FROM 起点 TO 终点 STEP 步长 DRAW(x,y);\n    FOR = 'FOR'\n    FROM = 'FROM'\n    TO = 'TO'\n    STEP = 'STEP'\n    DRAW = 'DRAW'\n    SCATTER = 'SCATTER'\n    ## ORIGIN IS (x, y)\n    ORIGIN = 'ORIGIN'\n    IS = 'IS'\n    ## ROT IS (X, Y)\n    ROT = 'ROT'\n    ## SCALE IS (X,Y)\n    SCALE = 'SCALE'\n    ## IN [COLOR_NAME]\n    IN = 'IN'\n    COLOR = 'COLOR'\n    ## LINE[LINE_WIDTH][LINE_TYPE]\n    LINE = 'LINE'\n    LINE_TYPE = 'LINE_TYPE'\n    ## TITLE('USER_STRING')\n    TITLE = 'TITLE'\n    USER_STRING = 'USER_STRING'\n    ## XLABEL('USER_STRING'), YLABEL('USER_STRING')\n    XLABEL = 'XLABEL'\n    YLABEL = 'YLABEL'\n    ## GRID ON GRID OFF\n    GRID = 'GRID'\n    ON = 'ON'\n    OFF = 'OFF'\n    ## DYNAMIC ON DYNAMIC OFF\n    DYNAMIC = 'DYNAMIC'\n    # 分隔符\n    SEMICO = \";\"\n    L_BRACKET = \"(\"\n    R_BRACKET = \")\"\n    COMMA = \",\"\n    # 运算符\n    PLUS = '+'\n    MINUS = '-'\n    MUL = '*'\n    DIV = '/'\n    MOD = '%'\n    POWER = '**'\n    # 空记号 源程序结束\n    NONTOKEN = 'NULL'\n    # 出错符号，非法输入\n    ERRORTOKEN = 'ERROR'\n\n\nclass Tokens:\n    # 构造函数，默认情况下值为0，函数指针指向空\n    def __init__(self, tokenType, lexeme, value = 0.0, function = None):\n        self.tokenType = tokenType\n        self.lexeme = lexeme\n        self.value = value\n        self.function = function\n    # 展示token的内容，便于调试\n    def disp(self):\n        # print('{:<10s}|{:x<10s}|{:<10f}|{}'.format(self.tokenType.name,  self.lexeme, self.value, self.function))\n        print('{:<30s}|{:<28s}\\t|{:<10f}|{}'.format(self.tokenType.name,  self.lexeme, self.value, self.function))\n\nTokenTable = {\n    # 常量：COUST_ID\n    \"PI\" : Tokens(TokenType.CONST_ID, \"PI\", 3.1415926, None),\n    \"E\"  : Tokens(TokenType.CONST_ID,\"E\",2.71828,None),\n    # 唯一变量T ：T\n    \"T\"  : Tokens(TokenType.T, \"T\"),\n    # 函数\n    \"SIN\": Tokens(TokenType.FUNC, \"SIN\", 0, np.sin),\n    \"COS\": Tokens(TokenType.FUNC, \"COS\", 0, np.cos),\n    \"TAN\": Tokens(TokenType.FUNC, \"TAN\", 0, np.tan),\n    \"SQRT\": Tokens(TokenType.FUNC, \"SQRT\", 0, np.sqrt),\n    \"EXP\": Tokens(TokenType.FUNC, \"EXP\", 0, np.exp),\n    \"LN\": Tokens(TokenType.FUNC, \"LN\", 0, np.log),\n    # 保留关键字\n    \"ORIGIN\":Tokens(TokenType.ORIGIN, \"ORIGIN\"),\n    \"IS\":Tokens(TokenType.IS, \"IS\"),\n    \"ROT\":Tokens(TokenType.ROT, \"ROT\"),\n    \"SCALE\":Tokens(TokenType.SCALE, \"SCALE\"),\n    \"FOR\":Tokens(TokenType.FOR, \"FOR\"),\n    \"FROM\":Tokens(TokenType.FROM, \"FROM\"),\n    \"TO\":Tokens(TokenType.TO, \"TO\"),\n    \"STEP\":Tokens(TokenType.STEP,\"STEP\"),\n    \"DRAW\":Tokens(TokenType.DRAW, \"DRAW\"),\n    \"SCATTER\":Tokens(TokenType.SCATTER,\"SCATTER\"),\n    \"COLOR\":Tokens(TokenType.COLOR, \"COLOR\"),\n    \"LINE\":Tokens(TokenType.LINE,\"LINE\"),\n    \"DOTS\":Tokens(TokenType.LINE_TYPE,\"DOTS\"),\n    \"DASHED\":Tokens(TokenType.LINE_TYPE,\"DASHED\"),\n    \"SOLID\":Tokens(TokenType.LINE_TYPE,\"SOLID\"),\n    \"XLABEL\":Tokens(TokenType.XLABEL,\"XLABEL\"),\n    \"YLABEL\":Tokens(TokenType.YLABEL,\"YLABEL\"),\n    \"TITLE\":Tokens(TokenType.TITLE,\"TITLE\"),\n    \"GRID\":Tokens(TokenType.GRID, \"GRID\"),\n    \"ON\":Tokens(TokenType.ON, \"ON\"),\n    \"OFF\":Tokens(TokenType.OFF, \"OFF\"),\n    \"DYNAMIC\":Tokens(TokenType.DYNAMIC, \"DYNAMIC\"),\n    # 颜色\n    \"DIMGRAY\":Tokens(TokenType.COLOR,\"DIMGRAY\"),\n    \"GOLDENROD\":Tokens(TokenType.COLOR,\"GOLDENROD\"),\n    \"KHAKI\":Tokens(TokenType.COLOR,\"KHAKI\"),\n    \"DARKSEAGREEN\":Tokens(TokenType.COLOR,\"DARKSEAGREEN\"),\n    \"DARKKHAKI\":Tokens(TokenType.COLOR,\"DARKKHAKI\"),\n    \"PINK\":Tokens(TokenType.COLOR,\"PINK\"),\n    \"LIGHTSALMON\":Tokens(TokenType.COLOR,\"LIGHTSALMON\"),\n    \"LIGHTCORAL\":Tokens(TokenType.COLOR,\"LIGHTCORAL\"),\n    \"IN\":Tokens(TokenType.IN, \"IN\")\n}`\nexport default {\n  name: \"Parser\",\n  data() {\n    return {\n      title1: \"Lexer.py\",\n      title: \"Token.py\",\n      code,\n      code1,\n      cmOptions: {\n        autoCloseBrackets: true,\n        tabSize: 4,\n        styleActiveLine: true,\n        lineNumbers: true,\n        line: true,\n        mode: \"text/x-python\",\n        theme: \"idea\",\n        keyMap: \"emacs\",\n      },\n      option: {},\n      updateOption: {},\n      isImage: false,\n      isError: false,\n      isSuccess: false,\n      errorMsg: \"\",\n      successMsg: \"\",\n      collapsed: false,\n    };\n  },\n  methods: {\n    onCmReady(cm) {\n      console.log(\"the editor is readied!\", cm);\n    },\n    onCmFocus(cm) {\n      console.log(\"the editor is focused!\", cm);\n    },\n    onCmCodeChange(newCode) {\n      console.log(\"this is new code\", newCode);\n      this.code = newCode;\n    },\n  },\n  computed: {},\n  mounted() {},\n  components: {},\n};\n</script>\n\n<style>\n.CodeMirror {\n  height: 800px !important;\n}\n.CodeMirror-focused .cm-matchhighlight {\n  background-image: url(data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAAAIAAAACCAYAAABytg0kAAAAFklEQVQI12NgYGBgkKzc8x9CMDAwAAAmhwSbidEoSQAAAABJRU5ErkJggg==);\n  background-position: bottom;\n  background-repeat: repeat-x;\n}\n.cm-matchhighlight {\n  background-color: lightgreen;\n}\n.CodeMirror-selection-highlight-scrollbar {\n  background-color: green;\n}\n</style>\n","import mod from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Lexer.vue?vue&type=script&lang=js&\"; export default mod; export * from \"-!../../node_modules/cache-loader/dist/cjs.js??ref--13-0!../../node_modules/thread-loader/dist/cjs.js!../../node_modules/babel-loader/lib/index.js!../../node_modules/cache-loader/dist/cjs.js??ref--1-0!../../node_modules/vue-loader/lib/index.js??vue-loader-options!./Lexer.vue?vue&type=script&lang=js&\"","import { render, staticRenderFns } from \"./Lexer.vue?vue&type=template&id=a2f5e812&\"\nimport script from \"./Lexer.vue?vue&type=script&lang=js&\"\nexport * from \"./Lexer.vue?vue&type=script&lang=js&\"\nimport style0 from \"./Lexer.vue?vue&type=style&index=0&lang=css&\"\n\n\n/* normalize component */\nimport normalizer from \"!../../node_modules/vue-loader/lib/runtime/componentNormalizer.js\"\nvar component = normalizer(\n  script,\n  render,\n  staticRenderFns,\n  false,\n  null,\n  null,\n  null\n  \n)\n\nexport default component.exports"],"sourceRoot":""}